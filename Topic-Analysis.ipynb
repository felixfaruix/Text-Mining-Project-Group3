{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb683c59",
   "metadata": {},
   "source": [
    "# Topic Analysis - Project Assignment Group 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c1508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd \n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import pickle \n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9289e0",
   "metadata": {},
   "source": [
    "### Dataset Inspection and Content Extraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c987e2",
   "metadata": {},
   "source": [
    "In the first part of our Topic Analysis section of the project, we will extract all the sections in the database and count them to see what each news article is assigned to. In this way, we can choose our topics and see what we are first counting.\n",
    "\n",
    "We will notice that the _section_ column in the dataset is not helpful, since it groups the articles in a sparse way and does not provide useful labels for our topic classification.\n",
    "\n",
    "Thus, we will have to preprocess each article by first extracting the _content_ column from each (ignoring all the others) In this way we will feed our LDA model for topic analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = get_dataset_config_names(\"RealTimeData/bbc_news_alltime\")\n",
    "\n",
    "all_sections = []\n",
    "\n",
    "for month in subfolders:\n",
    "    dataset = load_dataset(\"RealTimeData/bbc_news_alltime\", month, split=\"train\")\n",
    "    if \"section\" in dataset.column_names:\n",
    "        all_sections.extend(dataset[\"section\"])\n",
    "\n",
    "section_df = pd.DataFrame(all_sections, columns=[\"section\"])\n",
    "section_counts = section_df[\"section\"].value_counts(dropna=False).reset_index()\n",
    "section_counts.columns = [\"Topic\", \"Count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_counts = section_df['section'].value_counts(dropna=False).reset_index()\n",
    "section_counts.columns = ['Topic', 'Count']\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(section_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841ac7d",
   "metadata": {},
   "source": [
    "Loading SpaCy, getting the dataset and splitting between test and train folders (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe29be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = get_dataset_config_names(\"RealTimeData/bbc_news_alltime\")\n",
    "preprocessing = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "preprocessing.add_pipe(\"sentencizer\")\n",
    "random.seed(42)\n",
    "selected_months = random.sample(subfolders, k=20)\n",
    "\n",
    "#Splitting the folders in train and test sets based on months folders \n",
    "train_months, test_months = train_test_split(selected_months, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "\n",
    "# Looping over the months folders\n",
    "for month in tqdm(train_months, desc=\"Month\"): \n",
    "    dataset = load_dataset(\"RealTimeData/bbc_news_alltime\", month, split=\"train\")\n",
    "    # Looping over the various articles\n",
    "    content = [article[\"content\"] for article in dataset] \n",
    "    # Getting the Doc object of the article and looping over them splittin the sentences\n",
    "    for doc in preprocessing.pipe(content, batch_size=32):\n",
    "        for sent in doc.sents:\n",
    "            text = sent.text.strip()\n",
    "            if text:\n",
    "                print(text)\n",
    "                train_sentences.append(text)\n",
    "\n",
    "print(train_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682644b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theresa May was in Poland to sign a defence treaty with the country\n",
      "\n",
      "Theresa May has sought to reassure Polish people living in the UK that they are still welcome after Brexit.\n",
      "Speaking on a trip to Warsaw to sign a new defence treaty with the country, the PM said the one million Polish residents were a \"strong part of [UK] society\".\n",
      "She promised a \"simple\" and \"easy\" process to get \"settled status\" to remain after the UK leaves the EU.\n",
      "The trip comes after Mrs May sacked one of her closest allies, Damian Green.\n",
      "She asked him to leave after he made \"misleading\" statements about claims pornography was found on his parliamentary computer.\n"
     ]
    }
   ],
   "source": [
    "for x in train_sentences[:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0805123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273a167b60814c8fba2e419746141f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Months Analyzed:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we are applying the same procedure for the test set in the test_months folder \n",
    "test_sentences = []\n",
    "\n",
    "for month in tqdm(test_months, desc=\"Months Analyzed\"): \n",
    "    dataset = load_dataset(\"RealTimeData/bbc_news_alltime\", month, split=\"train\")\n",
    "    # Looping over the various articles\n",
    "    content = [article[\"content\"] for article in dataset] \n",
    "    # Getting the Doc object of the article and looping over them splittin the sentences\n",
    "    for doc in preprocessing.pipe(content, batch_size=32):\n",
    "        for sent in doc.sents:\n",
    "            text = sent.text.strip()\n",
    "            if text:\n",
    "                test_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc18c1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amiram Cooper, Guy Gilboa-Dalal and Tsachi Idan are being held in Gaza\n",
      "\n",
      "Israel says 129 people remain unaccounted for after they were abducted and taken to Gaza during the October 7 attacks by Hamas.\n",
      "Of these, Israel says that 22 are believed to be dead.\n",
      "A group representing the families of hostages says that Gadi Haggai, 73, is now believed to have died in Gaza.\n",
      "An estimated 240 people were taken prisoner, but 105 were later released by Hamas during a six-day ceasefire at the end of November.\n",
      "These are the stories of those hostages who are still being held, which have either been confirmed by the BBC or credibly reported.\n"
     ]
    }
   ],
   "source": [
    "for x in test_sentences[:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f987783",
   "metadata": {},
   "source": [
    "### Data Preprocessing using SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72950a4c",
   "metadata": {},
   "source": [
    "In this **preprocessing** stage, we transform raw sentences into clean, *lemmatized* tokens optimized for topic modeling. Specifically, we use **SpaCy** to tokenize and lemmatize each sentence, removing stopwords, punctuation, short words, and numbers. \n",
    "\n",
    "We also exclude tokens based on their linguistic roles (pronouns, determiners, prepositions, auxiliaries) and named entities (people, organizations, locations, dates, times). Then, we filter out domain-specific noise such as media sources (\"BBC\", \"Reuters\"), common journalistic fillers (\"said\", \"today\"), possessive pronouns, and country names using a custom exclusion list. \n",
    "\n",
    "The resulting cleaned tokens are then structured into a **Gensim-compatible dictionary and corpus**, ready for training the LDA model. \n",
    "This also takes into account the labels in the test set provided for the project. In fact, our goal is to align as closely as possible to the topics shown in that test set. Thus, we cut out all the noise we think we may encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a2dc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos_ner = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])\n",
    "stopwords = token_pos_ner.Defaults.stop_words\n",
    "\n",
    "countries_list= {country.name.lower() for country in pycountry.countries}\n",
    "\n",
    "# Excluding some words that are indeed part of newspapers articles but not necessary\n",
    "custom_stop = {\n",
    "    \"bbc\",\"reuters\",\"cnn\",\"guardian\",\"nytimes\",\"telegraph\",\"aljazeera\",\n",
    "    \"news\",\"press\",\"article\",\"media\",\"coverage\",\"broadcast\",\"report\",\"headline\",\n",
    "    \"says\",\"said\",\"told\",\"claim\",\"claimed\",\"statement\",\n",
    "    \"thing\",\"stuff\",\"someone\",\"anyone\",\"everyone\",\"something\",\"everything\",\n",
    "    \"kind\",\"sort\",\"part\",\"place\",\"area\",\"around\"\n",
    "}\n",
    "\n",
    "# Unifying the various exclusions we listed above (costumized)\n",
    "all_exclusions = stopwords.union(custom_stop).union(countries_list)\n",
    "pos_exclusions  = {\"PRON\",\"DET\",\"ADP\",\"AUX\",\"INTJ\"}\n",
    "entities_excl   = {\"PERSON\",\"ORG\",\"GPE\",\"LOC\",\"DATE\",\"TIME\"}\n",
    "\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    This function preprocesses sentences coming from test/train lists. \n",
    "    It removes the PoS tags adn entity labels listed above. It also removes unecessary words \n",
    "    that are not helpful for our topic analysis\n",
    "    \"\"\"\n",
    "\n",
    "    token_lists, cleaned_strings = [], []\n",
    "\n",
    "    for i in tqdm(range(0, len(train_sentences), 500), desc=\"Sentence batches\"):\n",
    "\n",
    "        batch_sents = train_sentences[i : i + 500]\n",
    "\n",
    "        for article in token_pos_ner.pipe(batch_sents, batch_size=16): \n",
    "            tokens = [token.lemma_.lower() for token in article if token.lemma_.lower() not in all_exclusions\n",
    "                and len(token) > 3\n",
    "                and not token.is_punct\n",
    "                and not token.like_num\n",
    "                and token.pos_ not in pos_exclusions\n",
    "                and token.ent_type_ not in entities_excl]\n",
    "            token_lists.append(tokens)\n",
    "            cleaned_strings.append(\" \".join(tokens))\n",
    "\n",
    "    return token_lists, cleaned_strings\n",
    "\n",
    "def preprocessing_test(sentence):\n",
    "    \"\"\"\n",
    "    This function preprocesses sentences coming from test/train lists. \n",
    "    It removes the PoS tags adn entity labels listed above. It also removes unecessary words \n",
    "    that are not helpful for our topic analysis\n",
    "    \"\"\"\n",
    "\n",
    "    token_lists, cleaned_strings = [], []\n",
    "\n",
    "    for i in tqdm(range(0, len(test_sentences), 500), desc=\"Sentence batches\"):\n",
    "\n",
    "        batch_sents = test_sentences[i : i + 500]\n",
    "\n",
    "        for article in token_pos_ner.pipe(batch_sents, batch_size=16): \n",
    "            tokens = [token.lemma_.lower() for token in article if token.lemma_.lower() not in all_exclusions\n",
    "                and len(token) > 3\n",
    "                and not token.is_punct\n",
    "                and not token.like_num\n",
    "                and token.pos_ not in pos_exclusions\n",
    "                and token.ent_type_ not in entities_excl]\n",
    "            token_lists.append(tokens)\n",
    "            cleaned_strings.append(\" \".join(tokens))\n",
    "\n",
    "    return token_lists, cleaned_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304aec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tokens_string = preprocessing(train_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4a1e8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed69877cfcb413d86f97188ed00b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentence batches:   0%|          | 0/443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokens, test_tokens_string = preprocessing_test(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce6d94",
   "metadata": {},
   "source": [
    "### Checkpoint \n",
    "\n",
    "(The Variable is too heavy to reload the process every time, so we saved the variables in a pkl file we can use it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the variables for later usage, in order to not loose the preprocessing \n",
    "with open(\"train_processed.pkl\", \"wb\") as f: \n",
    "    pickle.dump({\"tokens\": train_tokens, \n",
    "                 \"strings\": train_tokens_string}, f) \n",
    "    \n",
    "# Saving the variables for later usage, in order to not loose the preprocessing \n",
    "with open(\"test_processed.pkl\", \"wb\") as f: \n",
    "    pickle.dump({\"tokens\": test_tokens, \n",
    "                 \"strings\": test_tokens_string}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_processed.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_tokens = data[\"tokens\"]\n",
    "train_token_strings = data[\"strings\"]\n",
    "\n",
    "with open(\"test_processed.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_tokens = data[\"tokens\"]\n",
    "train_token_strings = data[\"strings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d338caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['theresa', 'sign', 'defence', 'treaty', 'country', 'theresa', 'seek', 'reassure', 'polish', 'people', 'live', 'welcome']\n",
      "['speak', 'trip', 'sign', 'defence', 'treaty', 'country', 'polish', 'resident', 'strong', 'society']\n",
      "['promise', 'simple', 'easy', 'process', 'settle', 'status', 'remain', 'leave']\n",
      "['trip', 'come', 'sack', 'close', 'ally']\n",
      "['ask', 'leave', 'misleading', 'pornography', 'find', 'parliamentary', 'computer']\n"
     ]
    }
   ],
   "source": [
    "for sentence in (train_tokens[:5]): \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ca1fd",
   "metadata": {},
   "source": [
    "### Training LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49746ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dictionary\u001b[38;5;241m.\u001b[39mfilter_extremes(no_below\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, no_above\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      3\u001b[0m bow_dict \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m train_tokens]\n\u001b[1;32m----> 5\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbow_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2word\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tid, topic \u001b[38;5;129;01min\u001b[39;00m lda_model\u001b[38;5;241m.\u001b[39mprint_topics(num_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\felix\\Anaconda\\envs\\ML_VU\\lib\\site-packages\\gensim\\models\\ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\felix\\Anaconda\\envs\\ML_VU\\lib\\site-packages\\gensim\\models\\ldamodel.py:991\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    988\u001b[0m reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m--> 991\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlencorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher:\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;66;03m# add the chunk to dispatcher's job queue, so workers can munch on it\u001b[39;00m\n\u001b[0;32m    995\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, dispatching documents up to #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    997\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m    998\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\felix\\Anaconda\\envs\\ML_VU\\lib\\site-packages\\gensim\\models\\ldamodel.py:847\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    845\u001b[0m corpus_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cnt \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m chunk \u001b[38;5;28;01mfor\u001b[39;00m _, cnt \u001b[38;5;129;01min\u001b[39;00m document)\n\u001b[0;32m    846\u001b[0m subsample_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m total_docs \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m--> 847\u001b[0m perwordbound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsample_ratio\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m (subsample_ratio \u001b[38;5;241m*\u001b[39m corpus_words)\n\u001b[0;32m    848\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m per-word bound, \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m documents with \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    850\u001b[0m     perwordbound, np\u001b[38;5;241m.\u001b[39mexp2(\u001b[38;5;241m-\u001b[39mperwordbound), \u001b[38;5;28mlen\u001b[39m(chunk), corpus_words\n\u001b[0;32m    851\u001b[0m )\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[1;32mc:\\Users\\felix\\Anaconda\\envs\\ML_VU\\lib\\site-packages\\gensim\\models\\ldamodel.py:1113\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbound: at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, d)\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1113\u001b[0m     gammad, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1115\u001b[0m     gammad \u001b[38;5;241m=\u001b[39m gamma[d]\n",
      "File \u001b[1;32mc:\\Users\\felix\\Anaconda\\envs\\ML_VU\\lib\\site-packages\\gensim\\models\\ldamodel.py:729\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    728\u001b[0m gamma[d, :] \u001b[38;5;241m=\u001b[39m gammad\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m gammad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collect_sstats:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# Contribution of document d to the expected sufficient\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# statistics for the M step.\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     sstats[:, ids] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(expElogthetad\u001b[38;5;241m.\u001b[39mT, cts \u001b[38;5;241m/\u001b[39m phinorm)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "dictionary = corpora.Dictionary(train_tokens)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "bow_dict = [dictionary.doc2bow(doc) for doc in train_tokens]\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "lda_model = models.LdaModel(corpus = bow_dict, id2word = dictionary, num_topics = 10, passes = 10, random_state = 42, eval_every = 1, per_word_topics   = True)\n",
    "\n",
    "for tid, topic in lda_model.print_topics(num_words=10):\n",
    "    print(f\"Topic {tid}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8066e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 1.  Pretty-print top words per topic\n",
    "# --------------------------------------------------\n",
    "def show_top_words(model, dictionary, n_words=10):\n",
    "    print(\"TOP WORDS PER TOPIC\\n\" + \"-\"*30)\n",
    "    for tid, topic in model.show_topics(num_topics=model.num_topics,\n",
    "                                        num_words=n_words,\n",
    "                                        formatted=False):\n",
    "        words = \", \".join([w for w, p in topic])\n",
    "        print(f\"Topic {tid:>2} ▶ {words}\")\n",
    "\n",
    "show_top_words(lda_model, dictionary, n_words=12)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2.  Grab example sentences for each topic\n",
    "#     (using train_tokens + original raw sentence)\n",
    "# --------------------------------------------------\n",
    "import random, pandas as pd\n",
    "\n",
    "# Build a quick lookup of dominant topic per sentence\n",
    "dominant = [\n",
    "    max(lda_model.get_document_topics(dictionary.doc2bow(toks)),\n",
    "        key=lambda x: x[1])[0]\n",
    "    if toks else None\n",
    "    for toks in train_tokens\n",
    "]\n",
    "\n",
    "# Put into a DataFrame for easy filtering\n",
    "df_sent = pd.DataFrame({\n",
    "    \"sentence_raw\":   train_sentences,\n",
    "    \"topic_id\":       dominant\n",
    "})\n",
    "\n",
    "def print_examples(topic_id, k=5):\n",
    "    subset = df_sent[df_sent.topic_id == topic_id].sentence_raw\n",
    "    print(f\"\\nEXAMPLE SENTENCES for Topic {topic_id}\\n\" + \"-\"*30)\n",
    "    for sent in random.sample(list(subset), k=min(k, len(subset))):\n",
    "        print(\"•\", sent[:150].strip() + (\"…\" if len(sent) > 150 else \"\"))\n",
    "\n",
    "# Show 3 examples for each topic\n",
    "for tid in range(lda_model.num_topics):\n",
    "    print_examples(tid, k=3)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3.  (Optional) Interactive pyLDAvis\n",
    "# --------------------------------------------------\n",
    "# !pip install pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()  # in Jupyter/Colab\n",
    "vis = gensimvis.prepare(lda_model, bow_corpus, dictionary)\n",
    "vis  # displays the interactive panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df00529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1.  <<< MANUAL MAPPING:  fill after inspection >>>\n",
    "# ------------------------------------------------\n",
    "topic_to_label = {\n",
    "    2: \"sports\",\n",
    "    7: \"movie\",\n",
    "    4: \"book\",\n",
    "    # add others or map unused to \"other\"\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2.  Build summary table\n",
    "# ------------------------------------------------\n",
    "def top_words(model, topic_id, n=8):\n",
    "    return \", \".join([dictionary[id] for id, _ in model.get_topic_terms(topic_id, n)])\n",
    "\n",
    "rows = []\n",
    "for tid in range(lda_model.num_topics):\n",
    "    label = topic_to_label.get(tid, \"other\")\n",
    "    rows.append({\n",
    "        \"Topic ID\": tid,\n",
    "        \"Assigned label\": label,\n",
    "        \"Top words\": top_words(lda_model, tid, 10),\n",
    "        \"Train sentences\": sum(1 for t in dominant if t == tid)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(\"Topic ID\")\n",
    "display(summary_df)          # Jupyter display\n",
    "# Or: print(summary_df.to_markdown(index=False))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3-A.  Topic-coherence (C_v)\n",
    "# ------------------------------------------------\n",
    "coh_model = CoherenceModel(\n",
    "    model=lda_model, texts=train_tokens,\n",
    "    dictionary=dictionary, coherence='c_v'\n",
    ")\n",
    "overall_cv = coh_model.get_coherence()\n",
    "per_topic_cv = coh_model.get_coherence_per_topic()\n",
    "print(f\"Overall C_v coherence: {overall_cv:.3f}\")\n",
    "for tid, score in enumerate(per_topic_cv):\n",
    "    print(f\"  Topic {tid:2d}: C_v = {score:.3f}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3-B.  Classification scores on professor’s test set\n",
    "# ------------------------------------------------\n",
    "#  → assumes you have gold labels in test_gold (list[str])\n",
    "test_topic_id = [\n",
    "    max(lda_model.get_document_topics(dictionary.doc2bow(tok)), key=lambda x: x[1])[0]\n",
    "    if tok else None\n",
    "    for tok in test_tokens\n",
    "]\n",
    "test_pred_label = [topic_to_label.get(tid, \"other\") for tid in test_topic_id]\n",
    "\n",
    "print(classification_report(test_gold, test_pred_label, zero_division=0))\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(test_gold, test_pred_label))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4.  Qualitative sample sentences\n",
    "# ------------------------------------------------\n",
    "def print_examples(topic_id, k=3):\n",
    "    idx = [i for i, tid in enumerate(test_topic_id) if tid == topic_id][:k]\n",
    "    print(f\"\\nExamples for topic {topic_id} ({topic_to_label.get(topic_id,'other')}):\")\n",
    "    for i in idx:\n",
    "        print(\" •\", test_sentences[i][:150])\n",
    "\n",
    "for tid in topic_to_label:\n",
    "    print_examples(tid, k=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_VU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
