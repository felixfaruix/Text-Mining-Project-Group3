{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db770b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0 | Entity: 'Paris' | Label: LOC | Span: (19, 24)\n",
      "Sentence 0 | Entity: 'Louvre' | Label: PER | Span: (48, 54)\n",
      "Sentence 0 | Entity: 'the Mona Lisa' | Label: MISC | Span: (73, 86)\n",
      "Sentence 1 | Entity: 'Amazon' | Label: ORG | Span: (0, 6)\n",
      "Sentence 1 | Entity: 'Google' | Label: ORG | Span: (9, 15)\n",
      "Sentence 1 | Entity: 'Meta' | Label: ORG | Span: (20, 24)\n",
      "Sentence 2 | Entity: 'Pharoah Sanders' | Label: PER | Span: (13, 28)\n",
      "Sentence 2 | Entity: 'Floating Points' | Label: MISC | Span: (52, 67)\n",
      "Sentence 4 | Entity: 'Kevin' | Label: PER | Span: (10, 15)\n",
      "Sentence 4 | Entity: 'Succession' | Label: MISC | Span: (39, 49)\n",
      "Sentence 4 | Entity: 'Kieran Culkin 's' | Label: PER | Span: (81, 97)\n",
      "Sentence 5 | Entity: 'Venus Williams' | Label: PER | Span: (0, 14)\n",
      "Sentence 6 | Entity: 'Elizabeth' | Label: PER | Span: (12, 21)\n",
      "Sentence 6 | Entity: 'King Charles' | Label: PER | Span: (29, 41)\n",
      "Sentence 6 | Entity: 'the British Royal Family' | Label: ORG | Span: (63, 87)\n",
      "Sentence 7 | Entity: 'Dark Souls' | Label: PER | Span: (30, 40)\n",
      "Sentence 8 | Entity: 'America' | Label: LOC | Span: (63, 70)\n",
      "Sentence 9 | Entity: 'Michael Jordan' | Label: PER | Span: (0, 14)\n",
      "Sentence 9 | Entity: 'one' | Label: MISC | Span: (29, 32)\n",
      "Sentence 9 | Entity: 'NBA' | Label: ORG | Span: (75, 78)\n",
      "Sentence 10 | Entity: 'New Amsterdam' | Label: LOC | Span: (21, 34)\n",
      "Sentence 10 | Entity: 'New York' | Label: LOC | Span: (57, 65)\n",
      "Sentence 11 | Entity: 'MMA' | Label: ORG | Span: (0, 3)\n",
      "Sentence 11 | Entity: 'John Cena' | Label: PER | Span: (37, 46)\n",
      "Sentence 11 | Entity: 'every day' | Label: MISC | Span: (78, 87)\n",
      "Sentence 12 | Entity: 'OK Computer' | Label: ORG | Span: (0, 11)\n",
      "Sentence 12 | Entity: 'the '90s' | Label: MISC | Span: (62, 70)\n",
      "Sentence 13 | Entity: 'Michael Phelps' | Label: PER | Span: (0, 14)\n",
      "Sentence 13 | Entity: 'the Olympic Games' | Label: MISC | Span: (41, 58)\n",
      "Sentence 14 | Entity: 'Ursula von der' | Label: PER | Span: (0, 14)\n",
      "Sentence 14 | Entity: 'Leyen' | Label: LOC | Span: (15, 20)\n",
      "Sentence 14 | Entity: 'the European Union Commission' | Label: ORG | Span: (49, 78)\n",
      "\n",
      "--- Evaluation ---\n",
      "Precision: 0.048\n",
      "Recall:    0.034\n",
      "F1-score:  0.040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "except:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  \n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"NER-test.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "label_map = {\n",
    "    \"PERSON\": \"PER\",\n",
    "    \"LOCATION\": \"LOC\",\n",
    "    \"ORGANIZATION\": \"ORG\",\n",
    "    \"ORG\": \"ORG\",\n",
    "    \"WORK_OF_ART\": \"MISC\",\n",
    "    \"EVENT\": \"MISC\",\n",
    "    \"PRODUCT\": \"MISC\",\n",
    "    \"DATE\": \"MISC\",\n",
    "    \"TIME\": \"MISC\",\n",
    "    \"MONEY\": \"MISC\",\n",
    "    \"PERCENT\": \"MISC\",\n",
    "}\n",
    "\n",
    "def convert_bio_tag(tag):\n",
    "    if tag == \"O\":\n",
    "        return tag\n",
    "    else:\n",
    "        prefix, typ = tag.split(\"-\", 1)\n",
    "        typ_mapped = label_map.get(typ, \"MISC\")\n",
    "        return f\"{prefix}-{typ_mapped}\"\n",
    "\n",
    "test_df[\"BIO_NER_tag\"] = test_df[\"BIO_NER_tag\"].apply(convert_bio_tag)\n",
    "\n",
    "test_sentences = []\n",
    "for sid, group in test_df.groupby(\"sentence_id\"):\n",
    "    sentence = \" \".join(group[\"token\"])\n",
    "    test_sentences.append((sid, sentence))\n",
    "\n",
    "predictions = []\n",
    "for sid, sent in test_sentences:\n",
    "    doc = nlp(sent)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PERSON\", \"PER\"]:\n",
    "            mapped = \"PER\"\n",
    "        elif ent.label_ in [\"ORG\", \"ORGANIZATION\"]:\n",
    "            mapped = \"ORG\"\n",
    "        elif ent.label_ in [\"GPE\", \"LOC\", \"LOCATION\"]:\n",
    "            mapped = \"LOC\"\n",
    "        else:\n",
    "            mapped = \"MISC\"\n",
    "        predictions.append((sid, ent.text, ent.start_char, ent.end_char, mapped))\n",
    "        print(f\"Sentence {sid} | Entity: '{ent.text}' | Label: {mapped} | Span: ({ent.start_char}, {ent.end_char})\")\n",
    "\n",
    "pred_df = pd.DataFrame(predictions, columns=[\"sentence_id\", \"entity\", \"start_char\", \"end_char\", \"label\"])\n",
    "pred_df.to_csv(\"ner_predictions_pretrained.csv\", index=False)\n",
    "\n",
    "# Evaluation: Precision, Recall, F1 \n",
    "\n",
    "def bio_to_spans(df):\n",
    "    spans = []\n",
    "    for sent_id, group in df.groupby(\"sentence_id\"):\n",
    "        tags = list(group[\"BIO_NER_tag\"])\n",
    "        tokens = list(group[\"token\"])\n",
    "        start = None\n",
    "        label = None\n",
    "        for i, tag in enumerate(tags):\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if start is not None:\n",
    "                    spans.append((sent_id, start, i-1, label))\n",
    "                start = i\n",
    "                label = tag[2:]\n",
    "            elif tag.startswith(\"I-\") and start is not None:\n",
    "                continue\n",
    "            else:\n",
    "                if start is not None:\n",
    "                    spans.append((sent_id, start, i-1, label))\n",
    "                    start = None\n",
    "                    label = None\n",
    "        if start is not None:\n",
    "            spans.append((sent_id, start, len(tags)-1, label))\n",
    "    return set(spans)\n",
    "\n",
    "gold_spans = bio_to_spans(test_df)\n",
    "\n",
    "# Map predictions to token indices\n",
    "sentence_tokens = {sid: list(group[\"token\"]) for sid, group in test_df.groupby(\"sentence_id\")}\n",
    "pred_spans = []\n",
    "for sid, tokens in sentence_tokens.items():\n",
    "    sent_text = \" \".join(tokens)\n",
    "    doc = nlp(sent_text)\n",
    "    char_to_token = []\n",
    "    pointer = 0\n",
    "    for idx, tok in enumerate(tokens):\n",
    "        pointer = sent_text.find(tok, pointer)\n",
    "        char_to_token.append((pointer, pointer + len(tok)))\n",
    "        pointer += len(tok)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PERSON\", \"PER\"]:\n",
    "            mapped = \"PER\"\n",
    "        elif ent.label_ in [\"ORG\", \"ORGANIZATION\"]:\n",
    "            mapped = \"ORG\"\n",
    "        elif ent.label_ in [\"GPE\", \"LOC\", \"LOCATION\"]:\n",
    "            mapped = \"LOC\"\n",
    "        else:\n",
    "            mapped = \"MISC\"\n",
    "        ent_start = ent_end = None\n",
    "        for idx, (start_char, end_char) in enumerate(char_to_token):\n",
    "            if ent_start is None and start_char >= ent.start:\n",
    "                ent_start = idx\n",
    "            if end_char > ent.end:\n",
    "                ent_end = idx\n",
    "                break\n",
    "        if ent_start is not None:\n",
    "            if ent_end is None:\n",
    "                ent_end = len(tokens) - 1\n",
    "            pred_spans.append((sid, ent_start, ent_end, mapped))\n",
    "\n",
    "pred_spans = set(pred_spans)\n",
    "\n",
    "tp = len(gold_spans & pred_spans)\n",
    "fp = len(pred_spans - gold_spans)\n",
    "fn = len(gold_spans - pred_spans)\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3120e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Anaconda)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
