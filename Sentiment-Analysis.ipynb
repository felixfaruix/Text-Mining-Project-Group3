{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a68054c",
   "metadata": {},
   "source": [
    "# Applying VADER for Sentence-Level Sentiment Detection in Social Media Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde41559",
   "metadata": {},
   "source": [
    "## Code implementation using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install simpletransformers\n",
    "!pip install vaderSentiment\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05163ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from transformers import pipeline \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset from Hugging Face's datasets\n",
    "dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "#Converting into vectors \n",
    "train_dataset = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    compound = vader_output['compound']\n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "def run_vader_spacy(textual_unit, lemmatize=False, pos_to_include=None, verbose=0):\n",
    "    doc = nlp(textual_unit)\n",
    "    input_tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if pos_to_include is None or token.pos_ in pos_to_include:\n",
    "            word = token.lemma_ if lemmatize else token.text\n",
    "            input_tokens.append(word)\n",
    "\n",
    "    processed_text = \" \".join(input_tokens)\n",
    "    scores = vader.polarity_scores(processed_text)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Input to VADER:\", processed_text)\n",
    "        print(\"Scores:\", scores)\n",
    "\n",
    "    return scores    \n",
    "\n",
    "#Matching the dataset's labels with their corresponding Sentiments \n",
    "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "train_dataset['gold_label'] = train_dataset['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying VADER method ot each tweet in the dataset \n",
    "def get_vader_label(row):\n",
    "    scores = run_vader_spacy(row['text'], lemmatize=True)\n",
    "    return vader_output_to_label(scores)\n",
    "\n",
    "\n",
    "#Applying VADER to each row in the dataset \n",
    "train_dataset['vader_label'] = train_dataset.apply(get_vader_label, axis=1)\n",
    "\n",
    "#Saving the file for qualitative and quantitative analysis\n",
    "train_dataset[['text', 'gold_label', 'vader_label']].to_csv(\"vader_sentiment_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54a5c9",
   "metadata": {},
   "source": [
    "## Quantitative Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e25c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.63      0.66      7781\n",
      "     neutral       0.74      0.43      0.54     11118\n",
      "    positive       0.55      0.89      0.68      8582\n",
      "\n",
      "    accuracy                           0.63     27481\n",
      "   macro avg       0.66      0.65      0.63     27481\n",
      "weighted avg       0.67      0.63      0.62     27481\n",
      "\n",
      "Accuracy: 0.6311\n"
     ]
    }
   ],
   "source": [
    "# Compare VADER predictions to gold labels\n",
    "y_true = train_dataset['gold_label']\n",
    "y_pred = train_dataset['vader_label']\n",
    "\n",
    "# Overall metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_VU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
